## **Description du projet**
Ce projet a √©t√© enti√®rement r√©alis√© sur **Google Colab**, permettant une ex√©cution **directe** des commandes **sans installation manuelle**.  
Il vise √† entra√Æner et √©valuer un **mod√®le de traduction neuronale** bas√© sur **OpenNMT** en utilisant des corpus bilingues anglais-fran√ßais.  

Nous explorons **deux approches linguistiques** :
1. **Mod√®le en forme fl√©chie** (mots conjugu√©s et accord√©s)
2. **Mod√®le en forme lemmatis√©e** (mots r√©duits √† leur racine lexicale)

L'objectif est d'analyser **l'impact de la lemmatisation** sur la qualit√© des traductions en utilisant le **score BLEU**.

 **Ex√©cution facile** : Copiez-collez chaque **cellule** de code dans un notebook **Google Colab** et ex√©cutez-la directement.  
 **Attention** : L'entra√Ænement du mod√®le peut √™tre long.  

### √âtape 1 : Installation des D√©pendances
 **√Ä ex√©cuter directement sur Colab**

```bash
!pip install torch torchvision torchaudio
!pip install OpenNMT-py sacrebleu stanza spacy

# Clone du d√©p√¥t Moses pour la normalisation
!git clone https://github.com/moses-smt/mosesdecoder.git

# T√©l√©chargement des mod√®les linguistiques
import stanza
stanza.download("en")  # Anglais
stanza.download("fr")  # Fran√ßais

import spacy
spacy.cli.download("en_core_web_sm")
spacy.cli.download("fr_core_news_sm")
```

---

###  √âtape 2 : V√©rification d'OpenNMT sur un Petit Corpus
**Test rapide sur un petit corpus anglais-allemand**

```bash
!wget https://s3.amazonaws.com/opennmt-trainingdata/toy-ende.tar.gz
!tar xf toy-ende.tar.gz
!cd toy-ende
!onmt_build_vocab -config toy_en_de.yaml -save_data toy_data
!onmt_train -config toy_en_de.yaml
!onmt_translate -model toy_model.pt -src toy_data/src-test.txt -output toy_data/pred.txt
!sacrebleu toy_data/tgt-test.txt -i toy_data/pred.txt -m bleu -b
```

---

###  √âtape 3 : Pr√©paration des Donn√©es
**T√©l√©chargement des corpus Europarl et EMEA et s√©paration des donn√©es**

```bash
!mkdir -p data/Europarl data/EMEA
!wget -O data/Europarl/en-fr.txt.zip https://object.pouta.csc.fi/OPUS-Europarl/v8/moses/en-fr.txt.zip
!unzip data/Europarl/en-fr.txt.zip -d data/Europarl

!wget -O data/EMEA/en-fr.txt.zip https://object.pouta.csc.fi/OPUS-EMEA/v3/moses/en-fr.txt.zip
!unzip data/EMEA/en-fr.txt.zip -d data/EMEA
```

 **S√©paration des donn√©es en ensembles d'entra√Ænement, validation et test**

```bash
!mkdir -p data/split

# Europarl
!head -100000 data/Europarl/Europarl.en-fr.en > data/split/Europarl_train_100k.en
!head -100000 data/Europarl/Europarl.en-fr.fr > data/split/Europarl_train_100k.fr

!tail -n +100001 data/Europarl/Europarl.en-fr.en | head -3750 > data/split/Europarl_dev_3750.en
!tail -n +100001 data/Europarl/Europarl.en-fr.fr | head -3750 > data/split/Europarl_dev_3750.fr

!tail -n +103751 data/Europarl/Europarl.en-fr.en | head -500 > data/split/Europarl_test_500.en
!tail -n +103751 data/Europarl/Europarl.en-fr.fr | head -500 > data/split/Europarl_test_500.fr

# EMEA
!head -10000 data/EMEA/EMEA.en-fr.en > data/split/Emea_train_10k.en
!head -10000 data/EMEA/EMEA.en-fr.fr > data/split/Emea_train_10k.fr

!tail -n +13751 data/EMEA/EMEA.en-fr.en | head -500 > data/split/Emea_test_500.en
!tail -n +13751 data/EMEA/EMEA.en-fr.fr | head -500 > data/split/Emea_test_500.fr
```

###  √âtape 4 : Entra√Ænement du Mod√®le (Forme Fl√©chie)

---

### **1Fichier de Configuration OpenNMT**

```yaml
%%writefile /content/opennmt_config.yaml
##  Donn√©es d'entra√Ænement et validation
data:
    corpus_1:
        path_src: /content/data/split/Europarl_train_100k.tok.true.clean.en
        path_tgt: /content/data/split/Europarl_train_100k.tok.true.clean.fr
        transforms: [filtertoolong]
        weight: 1
    valid:
        path_src: /content/data/split/Europarl_dev_3750.tok.true.en
        path_tgt: /content/data/split/Europarl_dev_3750.tok.true.fr
        transforms: [filtertoolong]

##  Vocabulaire
src_vocab: /content/data/opennmt/vocab.src
tgt_vocab: /content/data/opennmt/vocab.tgt

##  Mod√®le Transformer (Optimis√© pour le GPU A100 utilisable gr√¢ce √† Colab Pro)
model_task: seq2seq
model_type: text
encoder_type: transformer
decoder_type: transformer
layers: 6
heads: 8
hidden_size: 512
word_vec_size: 512
transformer_ff: 2048
dropout: 0.1

## Optimisation et acc√©l√©ration
optim: adam
learning_rate: 0.0005  #  R√©duction pour √©viter instabilit√©
warmup_steps: 4000
accum_count: 8  #  Accumulation pour simuler batch plus grand

##  Gestion efficace du batch et de la m√©moire GPU
batch_size: 1024  #  R√©duction pour √©viter OOM
valid_batch_size: 8
max_generator_batches: 2  #  √âconomie m√©moire pour l'inf√©rence
batch_type: "tokens"  #  Ajustement dynamique pour √©viter les pics m√©moire

##  Entra√Ænement et checkpoints
train_steps: 10000  #  √âviter surcharge m√©moire sur long training
valid_steps: 1000
save_checkpoint_steps: 2000
save_model: /content/model_opennmt/model

##  GPU et performance (Optimis√©)
gpu_ranks: [0]
world_size: 1
precision: "float16"  #  FP16 pour √©conomiser m√©moire
num_threads: 4  #  Chargement plus fluide
queue_size: 10000  #  √âquilibrage entre vitesse et m√©moire

##  Gestion avanc√©e de la m√©moire GPU
save_data: /content/model_opennmt
overwrite: True
disable_mem_redundancy: True  #  R√©duit la redondance m√©moire
exp_global_attn: True  #  Optimisation de l'attention pour m√©moire limit√©e
```

---

### **2Ô∏è Cr√©ation du Vocabulaire**
 **G√©n√©rer le vocabulaire utilis√© pour l'entra√Ænement.**

```bash
!onmt_build_vocab -config /content/opennmt_config.yaml -save_data /content/data/opennmt -n_sample 10000
```

---

### **3Ô∏è Entra√Ænement du Mod√®le**
 **Lancer l'entra√Ænement du mod√®le Transformer.**

```bash
!onmt_train -config /content/opennmt_config.yaml
```

---

### **4Ô∏è Traduction**
 **Utilisation du mod√®le entra√Æn√© pour traduire les phrases de test.**

```bash
!onmt_translate -model /content/model_opennmt/model_step_10000.pt \
                -src /content/data/split/Europarl_test_500.tok.true.en \
                -output /content/data/split/Europarl_test_500_translated.fr \
                -gpu 0
```

---

### **5Ô∏è √âvaluation avec SacreBLEU**
 **Calcul de la qualit√© de la traduction √† l'aide du score BLEU.**

```bash
!sacrebleu /content/data/split/Europarl_test_500.tok.true.fr \
           -i /content/data/split/Europarl_test_500_translated.fr \
           -m bleu -b --force
```

###  √âtape 5 : Entra√Ænement du Mod√®le (Forme Lemmatis√©e)

---

### **1Ô∏è Fichier de Configuration OpenNMT**

```yaml
%%writefile /content/opennmt_config.yaml
## Configuration pour corpus lemmatis√©
data:
    corpus_1:
        path_src: /content/data/split/Europarl_train_100k.lemma.en
        path_tgt: /content/data/split/Europarl_train_100k.lemma.fr
        transforms: [filtertoolong]
        weight: 1
    corpus_2:
        path_src: /content/data/split/Emea_train_10k.lemma.en
        path_tgt: /content/data/split/Emea_train_10k.lemma.fr
        transforms: [filtertoolong]
    valid:
        path_src: /content/data/split/Europarl_dev_3750.lemma.en
        path_tgt: /content/data/split/Europarl_dev_3750.lemma.fr
        transforms: [filtertoolong]

##  Param√®tres inchang√©s
src_vocab: /content/data/opennmt/vocab.src
tgt_vocab: /content/data/opennmt/vocab.tgt
train_steps: 10000
save_checkpoint_steps: 2000
save_model: /content/model_opennmt/model_lemma
gpu_ranks: [0]
world_size: 1
precision: "float16"
batch_size: 1024
```

---

### **2Ô∏è Fichier de Lemmatisation**
 **Ce script applique la lemmatisation sur tous les corpus avant l'entra√Ænement.**

```python
import spacy

# Charger les mod√®les SpaCy pour l'anglais et le fran√ßais
nlp_en = spacy.load("en_core_web_sm", disable=["ner", "parser"])
nlp_fr = spacy.load("fr_core_news_sm", disable=["ner", "parser"])

def lemmatize_file(input_file, output_file, nlp_model):
    """Applique la lemmatisation sur un fichier texte ligne par ligne."""
    with open(input_file, "r", encoding="utf-8") as f:
        lines = f.readlines()

    # Lemmatisation ligne par ligne
    lemmatized_lines = [" ".join([token.lemma_ for token in nlp_model(line)]) for line in lines]

    with open(output_file, "w", encoding="utf-8") as f:
        f.write("\n".join(lemmatized_lines))

# Lemmatisation des corpus Europarl et EMEA
for corpus in ["Europarl_train_100k", "Europarl_dev_3750", "Europarl_test_500",
               "Emea_train_10k", "Emea_test_500"]:
    lemmatize_file(f"data/split/{corpus}.en", f"data/split/{corpus}.lemma.en", nlp_en)
    lemmatize_file(f"data/split/{corpus}.fr", f"data/split/{corpus}.lemma.fr", nlp_fr)
```

Ex√©cutez ensuite la lemmatisation :

```bash
!python lemmatization.py
```

---

### **3Ô∏è Cr√©ation du Vocabulaire**
 **G√©n√©rer le vocabulaire utilis√© pour l'entra√Ænement.**

```bash
!onmt_build_vocab -config /content/opennmt_config.yaml -save_data /content/data/opennmt -n_sample 10000
```

---

### **4Ô∏è Entra√Ænement du Mod√®le**
 **Lancer l'entra√Ænement du mod√®le Transformer sur Colab avec les donn√©es lemmatis√©es.**

```bash
!onmt_train -config /content/opennmt_config.yaml
```

---

### **5Ô∏è Traduction**
 **Utilisation du mod√®le entra√Æn√© pour traduire les phrases de test (Europarl et EMEA).**

####  **Traduction Europarl**
```bash
!onmt_translate -model /content/model_opennmt/model_lemma_step_10000.pt \
                -src /content/data/split/Europarl_test_500.lemma.en \
                -output /content/data/split/Europarl_test_500_translated_lemma.fr \
                -gpu 0
```

#### üîπ **Traduction EMEA**
```bash
!onmt_translate -model /content/model_opennmt/model_lemma_step_10000.pt \
                -src /content/data/split/Emea_test_500.lemma.en \
                -output /content/data/split/Emea_test_500_translated_lemma.fr \
                -gpu 0
```

---

### **6Ô∏è √âvaluation avec SacreBLEU**
 **Calcul de la qualit√© de la traduction pour Europarl et EMEA.**

####  **√âvaluation Europarl**
```bash
!sacrebleu /content/data/split/Europarl_test_500.lemma.fr \
           -i /content/data/split/Europarl_test_500_translated_lemma.fr \
           -m bleu -b --force
```

####  **√âvaluation EMEA**
```bash
!sacrebleu /content/data/split/Emea_test_500.lemma.fr \
           -i /content/data/split/Emea_test_500_translated_lemma.fr \
           -m bleu -b --force
```
